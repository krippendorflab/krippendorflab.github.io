---
title: Data Driven Phenomenology for Beyond the Standard Model Physics
layout: page
description: 
---
At a very coarse level particle physics phenomenology is about writing down effective field theories to describe more and more aspects of the Universe we observe, and to find clever ways of testing these models.

The way we typically come up with new models seems rather baroque as we use more or less the same tools of well-defined building blocks for decades (symmetries, extra-dimensions, power-law scalings, etc.) which provide us with a "handful" of models to examine and use. I have done exactly this type of physics in the past (see my publication list).

This is at first sight in contradiction with the success of deep over-parameterized neural networks which show remarkable performance on many but clearly not all tasks. This contradiction due to over-parameterization can be overcome when we know what the neural network is calculating.

By trying to figure out which features your ML algorithm is using and which simple (i.e. compressed into few parameters) models are behind the solutions found by a neural network, my aim is to identify more accurate phenomenological models and to find new ways of testing existing models.

In particular, this is about constraining axion-like particles, one promising dark matter candidate, and this is about improving phenomenological models used in astrophysics to sharpen our predictions on \LambdaCDM cosmological parameters.
